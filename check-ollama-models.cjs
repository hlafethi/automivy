// Script pour v√©rifier les mod√®les install√©s sur Ollama (localai)
const fetch = require('node-fetch');
const path = require('path');
require('dotenv').config({ path: path.join(__dirname, '.env') });
require('dotenv').config({ path: path.join(__dirname, 'backend', '.env') });

async function checkOllamaModels() {
  // Essayer plusieurs URLs possibles
  const urls = [
    process.env.OLLAMA_URL,
    process.env.VITE_OLLAMA_URL,
    'http://147.93.58.155:19080', // Port mapp√© sur l'h√¥te (backend hors Docker)
    'http://localai:8080', // Port interne du conteneur (backend dans Docker)
    'http://localhost:19080',
    'http://127.0.0.1:19080'
  ].filter(Boolean); // Filtrer les valeurs nulles/undefined

  console.log('üîç V√©rification des mod√®les Ollama install√©s...\n');
  console.log('üìã URLs √† tester:');
  urls.forEach((url, index) => {
    console.log(`   ${index + 1}. ${url}`);
  });
  console.log('');

  for (const baseUrl of urls) {
    try {
      console.log(`üåê Test de connexion √†: ${baseUrl}`);
      
      const tagsUrl = `${baseUrl}/api/tags`;
      console.log(`   URL compl√®te: ${tagsUrl}`);
      
      const response = await fetch(tagsUrl, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json'
        },
        timeout: 5000
      });

      if (!response.ok) {
        console.log(`   ‚ùå Erreur HTTP ${response.status}: ${response.statusText}`);
        continue;
      }

      const data = await response.json();
      
      console.log(`   ‚úÖ Connexion r√©ussie!`);
      console.log(`   üì¶ Nombre de mod√®les trouv√©s: ${data.models?.length || 0}\n`);

      if (data.models && data.models.length > 0) {
        console.log('üìã Mod√®les install√©s:');
        console.log('‚îÄ'.repeat(60));
        data.models.forEach((model, index) => {
          console.log(`\n${index + 1}. Mod√®le: ${model.name}`);
          console.log(`   - Taille: ${(model.size / 1024 / 1024 / 1024).toFixed(2)} GB`);
          console.log(`   - Digest: ${model.digest?.substring(0, 12) || 'N/A'}...`);
          console.log(`   - Modifi√©: ${model.modified_at || 'N/A'}`);
        });
        console.log('\n' + '‚îÄ'.repeat(60));
        
        // Mod√®les compatibles avec l'AI Generator
        const compatibleModels = data.models.map(m => m.name).filter(name => {
          return name.includes('phi3') || 
                 name.includes('llama') || 
                 name.includes('mistral') || 
                 name.includes('codellama');
        });

        if (compatibleModels.length > 0) {
          console.log('\n‚úÖ Mod√®les compatibles avec l\'AI Generator:');
          compatibleModels.forEach(model => console.log(`   - ${model}`));
        } else {
          console.log('\n‚ö†Ô∏è  Aucun mod√®le compatible trouv√©.');
          console.log('   Mod√®les recommand√©s:');
          console.log('   - phi3:mini');
          console.log('   - phi3:3.8b');
          console.log('   - llama3.1:8b');
          console.log('   - mistral:7b');
          console.log('   - codellama:latest');
        }

        console.log(`\n‚úÖ URL fonctionnelle: ${baseUrl}`);
        console.log(`\nüîß Configuration recommand√©e dans backend/.env:`);
        console.log(`   OLLAMA_URL=${baseUrl}`);
        
        return; // Arr√™ter apr√®s le premier succ√®s
      } else {
        console.log(`   ‚ö†Ô∏è  Aucun mod√®le trouv√© sur ${baseUrl}`);
      }
    } catch (error) {
      console.log(`   ‚ùå Erreur: ${error.message}`);
      if (error.code === 'ENOTFOUND') {
        console.log(`      ‚Üí Le nom d'h√¥te "${baseUrl.split('://')[1].split(':')[0]}" ne peut pas √™tre r√©solu`);
        console.log(`      ‚Üí Utiliser l'IP VPS (147.93.58.155) si le backend n'est pas dans Docker`);
      } else if (error.code === 'ECONNREFUSED') {
        console.log(`      ‚Üí Connexion refus√©e - v√©rifier que Ollama est d√©marr√©`);
      } else if (error.code === 'ETIMEDOUT') {
        console.log(`      ‚Üí Timeout - v√©rifier la connectivit√© r√©seau`);
      }
      console.log('');
    }
  }

  console.log('\n‚ùå Aucune connexion r√©ussie.');
  console.log('\nüîç D√©pannage:');
  console.log('1. V√©rifier que le conteneur localai est d√©marr√©: docker ps | grep localai');
  console.log('2. V√©rifier le port mapp√©: docker ps | grep localai (colonne PORTS)');
  console.log('3. Si backend hors Docker, utiliser l\'IP VPS: OLLAMA_URL=http://147.93.58.155:19080');
  console.log('4. Si backend dans Docker, v√©rifier le r√©seau: docker network inspect <network_name>');
}

checkOllamaModels().catch(error => {
  console.error('‚ùå Erreur fatale:', error);
  process.exit(1);
});

